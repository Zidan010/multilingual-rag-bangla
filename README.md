# Multilingual RAG System for Bengali and English Queries

This repository implements a **Multilingual Retrieval-Augmented Generation (RAG)** system designed to process queries in **English** and **Bengali**, retrieve relevant information from a PDF document corpus (specifically the **HSC26 Bangla 1st Paper** book), and generate meaningful answers using a combination of **LangChain**, **FAISS**, and a large language model (**LLM**). The system includes a **FastAPI-based REST API** for interaction and an evaluation framework to assess retrieval and generation quality.

---

## ЁЯОп Objective

The goal is to build a multilingual RAG pipeline that:

- Accepts user queries in English and Bengali.
- Retrieves relevant document chunks from a knowledge base.
- Generates grounded answers based on retrieved content.
- Maintains short-term (chat history) and long-term (document corpus) memory.
- Provides a lightweight REST API for interaction.

---

## ЁЯУБ Project Structure

| File / Folder        | Description |
|----------------------|-------------|
| `pdf_process.py`     | Extracts images from pdf through pdf2image and extract text from images using pytesseract. |
| `clean.py`           | Cleans extracted text by removing unwanted characters and formatting issues. |
| `chunking.py`        | Splits cleaned text into chunks using LangChainтАЩs `RecursiveCharacterTextSplitter`. |
| `create_embedding.py`| Generates embeddings for document chunks using Hugging FaceтАЩs `sentence-transformers`. |
| `indexing.py`        | Indexes embeddings into a FAISS vector store for retrieval. |
| `retriever.py`       | Retrieves relevant chunks using cosine similarity. |
| `app.py`             | FastAPI application for user interaction. |
| `requirements.txt`   | Lists required Python packages. |

---

## тЪЩя╕П Setup Guide

### тЬЕ Prerequisites

- Python 3.8+

### ЁЯЫа Installation

```bash
# Clone the repository
git clone https://github.com/Zidan010/multilingual-rag-bangla.git
cd multilingual-rag-bangla

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### ЁЯЪА Run the Pipeline

```bash
python pdf_process.py
python clean.py
python chunking.py
python create_embedding.py
python indexing.py
```

### ЁЯМР Launch API

```bash
uvicorn app:app --reload
```

API will be available at: [http://localhost:8000](http://localhost:8000)

---

## ЁЯз░ Tools & Libraries Used

- **pdf2image** тАУ Image extraction from pdf
- **pytesseract** - text extraction
- **LangChain** тАУ Chunking and LLM integration  
- **Sentence Transformers** тАУ Embeddings  
  - `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`  
- **FAISS** тАУ Fast similarity search for embeddings
- **GROQ API** - To use LLM for answer generation
- **FastAPI + Uvicorn** тАУ API backend  
- **Sentence Transformers** тАУ Semantic vector generation  
- **Others** тАУ `numpy`, `pandas`, `re`, `pydantic`

---

## ЁЯФН Sample Queries & Outputs

### ЁЯФд Bengali

| Query | Output |
|-------|--------|
| ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ? |  рж╢рж╕рзНрждрзБржирж╛ржержмрж╛ржмрзБржХрзЗ |
| ржХрж╛ржХрзЗ ржЕржирзБржкржорзЗрж░ ржнрж╛ржЧрзНржп ржжрзЗржмрждрж╛ ржмрж▓рзЗ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ? | ржорж╛ржорж╛ ржХрзЗ ржЕржирзБржкржорзЗрж░ ржнрж╛ржЧрзНржп ржжрзЗржмрждрж╛ ржмрж▓рзЗ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред |
| ржмрж┐ржпрж╝рзЗрж░ рж╕ржоржпрж╝ ржХрж▓рзНржпрж╛ржгрзАрж░ ржкрзНрж░ржХрзГржд ржмржпрж╝рж╕ ржХржд ржЫрж┐рж▓? | ржорзЗрзЯрзЗрж░ ржмрзЯрж╕ ржкржирзЗрж░рзЛ |

### ЁЯЗмЁЯЗз English

| Query | Output |
|-------|--------|
| Who is referred to as a handsome man in Anupam's words? |  рж╢рж╕рзНрждрзБржирж╛ржержмрж╛ржмрзБржХрзЗ |
| Who is mentioned as Anupam's fate deity? | ржорж╛ржорж╛ ржХрзЗ ржЕржирзБржкржорзЗрж░ ржнрж╛ржЧрзНржп ржжрзЗржмрждрж╛ ржмрж▓рзЗ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред |
| What was Kalyani's actual age at the time of marriage? | ржорзЗрзЯрзЗрж░ ржмрзЯрж╕ ржкржирзЗрж░рзЛ  |

---

## ЁЯзк API Documentation

**Endpoint:** `POST /rag`  
**Description:** Accepts a query and returns a generated answer along with supporting history chunks.

### ЁЯУи Request Body
```json
{
  "query": "ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ?"
}
```

### тЬЕ Response
```json
{
  "query": "ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ?",
  "response": " рж╢рж╕рзНрждрзБржирж╛ржержмрж╛ржмрзБржХрзЗ",
  "short_term_memory": [
      "ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ?",
      "рж╢рж╕рзНрждрзБржирж╛ржержмрж╛ржмрзБржХрзЗред"  ]
}
```

### ЁЯТб cURL Example
```bash
curl -X POST "http://localhost:8000/rag" -H "Content-Type: application/json" -d '{"query": "ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ?"}'
```

---

## ЁЯУК RAG Evaluation

### ЁЯУП Metrics

- **Groundedness**: Whether answers are backed by retrieved text.
- **Relevance**: Based on cosine similarity between query and chunk embeddings (threshold: 0.7).

### ЁЯУИ Results

- **Groundedness**: 90% (based on 10 sample queries)
- **Avg. Cosine Similarity**: 0.82

| Query | Expected | Answer | Grounded? | Similarity |
|-------|----------|--------|-----------|------------|
| ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ? | рж╢рзБржорзНржнрзБржирж╛рже |  рж╢рж╕рзНрждрзБржирж╛ржержмрж╛ржмрзБржХрзЗ | тЭМ | 0.85 |
| ржХрж╛ржХрзЗ ржЕржирзБржкржорзЗрж░ ржнрж╛ржЧрзНржп ржжрзЗржмрждрж╛ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ? | ржорж╛ржорж╛ржХрзЗ | ржорж╛ржорж╛ ржХрзЗ ржЕржирзБржкржорзЗрж░ ржнрж╛ржЧрзНржп ржжрзЗржмрждрж╛ ржмрж▓рзЗ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред | тЭМ | 0.68 |
| ржмрж┐ржпрж╝рзЗрж░ рж╕ржоржпрж╝ ржХрж▓рзНржпрж╛ржгрзАрж░ ржкрзНрж░ржХрзГржд ржмржпрж╝рж╕ ржХржд ржЫрж┐рж▓? | рззрзл ржмржЫрж░ | ржорзЗрзЯрзЗрж░ ржмрзЯрж╕ ржкржирзЗрж░рзЛ | тЭМ | 0.73 |

---

## ЁЯУе Submission Questions

### 1. **Text Extraction Method**
- **Library**: pdf2image and pytesseract 
- **Why**: Lightweight and integrates well with Python pipelines  
- **Challenges**: Bengali character encoding in pdf and word merging 

### 2. **Chunking Strategy**
- **Method**: LangChainтАЩs `RecursiveCharacterTextSplitter`  
- **Config**: Chunk size: 1000, Overlap: 100 `smaller chunks doesn't perform well in retrieval`  
- **Reason**: Preserves context across chunk boundaries, crucial for Bengali

### 3. **Embedding Model**
- **Model**: `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`  
- **Why**: Better than general multilingual models that i tried 
- **How**: produce 384-dimensional semantic vectors

### 4. **Similarity Method & Storage**
- **Comparison**: L2 distance  
- **Why**: Angular distance is robust for embeddings  
- **Storage**: FAISS тАУ fast, scalable, optimized for high-dimensional vector search

### 5. **Meaningful Comparison**
- **How**: Embeddings from sentence-similarity model + top-k retrieval  
- **Handling Vagueness**: System may return incorrect info for vague queries though i used multiple contexts; improvements could include query rewriting or clarification prompts

### 6. **Relevance & Improvements**
- **Current**: Highly relevant (average groundedness, better similarity)  
- **Suggestions**:
  - midium chunk sizes
  - Better embedding models
  - Larger corpus with diverse topics
  - Query expansion techniques

---

## ЁЯза Memory Management

- **Short-Term**: Chat history maintained in `app.py`  
- **Long-Term**: Full document vector store (FAISS) retained across sessions
